The activation function used in the given programs are the sigmoid function.
However, in its stead, multiple other functions may also be used, such as ReLU, tanh and tan^-1h
However, given that the data st has an easily attainable max and minimum value, my opinion would be to use a linear function to scale the output.
This may be implemented by using a function of the type f(x) = mx
Here, m is a constant slope, determined based off of the inputs
In addition, a bell curve type of graph might also be useful.

When comparing the black box and white box neural networks, it can be found that the black box performs better consistently
This may be due to mistakes on the users end, unknown optimizations iside the black box, or a plethora of other reasons.
It can also be seen that, while the accuracy of the whitebox neural network goes up staedily with increases in training data,
The accuracy of the black box goes up exponentially in the beginning before plateauing in the high nineties
